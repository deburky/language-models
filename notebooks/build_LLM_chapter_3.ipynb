{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Build a Large Language Model (from scratch)\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\">\n",
    "\n",
    "Author of notes: https://github.com/deburky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Coding attention mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attention\n",
    "\n",
    "Self-attention serves as the cornerstone of every LLM based on the transformer architecture.\n",
    "\n",
    "Self-attention is a mechanism that allows each position in the input sequence to consider the relevancy of, or “attend to,” all other positions in the same sequence when computing the representation of a sequence. Self-attention is a key component of contemporary LLMs based on the transformer architecture, such as the GPT series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "In self-attention, our goal is to calculate context vectors <code>z(i)</code>\n",
       "    for each element <code>x(i)</code> in the input sequence. A context vector can be\n",
       "    interpreted as an enriched embedding vector."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8700</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6600</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.5500\u001b[0m, \u001b[1;36m0.8700\u001b[0m, \u001b[1;36m0.6600\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9544</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4950</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4754</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8434</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7070</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0865</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.9544\u001b[0m, \u001b[1;36m1.4950\u001b[0m, \u001b[1;36m1.4754\u001b[0m, \u001b[1;36m0.8434\u001b[0m, \u001b[1;36m0.7070\u001b[0m, \u001b[1;36m1.0865\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The main goal behind the normalization is to obtain attention weights that sum up to 1.\n",
       "    In practice, it's more common and advisable to use the softmax function for normalization."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Attention weights: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1385</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2379</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1240</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1082</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1581</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Attention weights: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1385\u001b[0m, \u001b[1;36m0.2379\u001b[0m, \u001b[1;36m0.2333\u001b[0m, \u001b[1;36m0.1240\u001b[0m, \u001b[1;36m0.1082\u001b[0m, \u001b[1;36m0.1581\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sum: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sum: \u001b[1;36m1.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next step is calculating the context vector <code>z(2)</code> by multiplying\n",
       "    the embedded input tokens, <code>x(i)</code>, with the corresponding attention weights\n",
       "    and then summing the resulting vectors. Thus, context vector <code>z(2)</code> is the \n",
       "    weighted sum of all input vectors, obtained by multiplying each input vector\n",
       "    by its corresponding attention weight:\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4419</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6515</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5683</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.4419\u001b[0m, \u001b[1;36m0.6515\u001b[0m, \u001b[1;36m0.5683\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from rich import print as rprint\n",
    "from IPython.display import HTML\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"In self-attention, our goal is to calculate context vectors <code>z(i)</code>\n",
    "    for each element <code>x(i)</code> in the input sequence. A context vector can be\n",
    "    interpreted as an enriched embedding vector.\"\"\"\n",
    "))\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "\n",
    "rprint(inputs.shape)\n",
    "\n",
    "# Dot product of each input vector with the query vector\n",
    "query = inputs[1]\n",
    "rprint(query)\n",
    "\n",
    "# Attention scores\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "rprint(attn_scores_2)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"The main goal behind the normalization is to obtain attention weights that sum up to 1.\n",
    "    In practice, it's more common and advisable to use the softmax function for normalization.\"\"\"\n",
    "))\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "rprint(f\"Attention weights: {attn_weights_2}\")\n",
    "rprint(f\"Sum: {attn_weights_2.sum()}\")\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"The next step is calculating the context vector <code>z(2)</code> by multiplying\n",
    "    the embedded input tokens, <code>x(i)</code>, with the corresponding attention weights\n",
    "    and then summing the resulting vectors. Thus, context vector <code>z(2)</code> is the \n",
    "    weighted sum of all input vectors, obtained by multiplying each input vector\n",
    "    by its corresponding attention weight:\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "# Calculate context vector z(2)\n",
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "rprint(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The dot product is a measure of similarity because it quantifies how closely two vectors are aligned: a higher dot product indicates a greater degree of alignment or similarity between the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "First, we calculate attention scores for each pair of input vectors. <br><br> Then,\n",
       "    we normalize the scores with softmax to obtain attention weights. <br><br>\n",
       "    Finally, we calculate the context vector by taking the weighted sum of the input vectors.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9995</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9544</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9422</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4753</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4576</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6310</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9544</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4950</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4754</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8434</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7070</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0865</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9422</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4754</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4570</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8296</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7154</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0605</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4753</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8434</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8296</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4937</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3474</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6565</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4576</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7070</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7154</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3474</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6654</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2935</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6310</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0865</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0605</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6565</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9450</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.9995\u001b[0m, \u001b[1;36m0.9544\u001b[0m, \u001b[1;36m0.9422\u001b[0m, \u001b[1;36m0.4753\u001b[0m, \u001b[1;36m0.4576\u001b[0m, \u001b[1;36m0.6310\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.9544\u001b[0m, \u001b[1;36m1.4950\u001b[0m, \u001b[1;36m1.4754\u001b[0m, \u001b[1;36m0.8434\u001b[0m, \u001b[1;36m0.7070\u001b[0m, \u001b[1;36m1.0865\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.9422\u001b[0m, \u001b[1;36m1.4754\u001b[0m, \u001b[1;36m1.4570\u001b[0m, \u001b[1;36m0.8296\u001b[0m, \u001b[1;36m0.7154\u001b[0m, \u001b[1;36m1.0605\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4753\u001b[0m, \u001b[1;36m0.8434\u001b[0m, \u001b[1;36m0.8296\u001b[0m, \u001b[1;36m0.4937\u001b[0m, \u001b[1;36m0.3474\u001b[0m, \u001b[1;36m0.6565\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4576\u001b[0m, \u001b[1;36m0.7070\u001b[0m, \u001b[1;36m0.7154\u001b[0m, \u001b[1;36m0.3474\u001b[0m, \u001b[1;36m0.6654\u001b[0m, \u001b[1;36m0.2935\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.6310\u001b[0m, \u001b[1;36m1.0865\u001b[0m, \u001b[1;36m1.0605\u001b[0m, \u001b[1;36m0.6565\u001b[0m, \u001b[1;36m0.2935\u001b[0m, \u001b[1;36m0.9450\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2098</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2006</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1981</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1242</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1220</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1452</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1385</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2379</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1240</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1082</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1581</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1390</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2369</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2326</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1242</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1108</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1565</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1435</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2074</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2046</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1462</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1263</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1720</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1958</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1975</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1367</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1879</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1295</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1385</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2184</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1420</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0988</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1896</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.2098\u001b[0m, \u001b[1;36m0.2006\u001b[0m, \u001b[1;36m0.1981\u001b[0m, \u001b[1;36m0.1242\u001b[0m, \u001b[1;36m0.1220\u001b[0m, \u001b[1;36m0.1452\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1385\u001b[0m, \u001b[1;36m0.2379\u001b[0m, \u001b[1;36m0.2333\u001b[0m, \u001b[1;36m0.1240\u001b[0m, \u001b[1;36m0.1082\u001b[0m, \u001b[1;36m0.1581\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1390\u001b[0m, \u001b[1;36m0.2369\u001b[0m, \u001b[1;36m0.2326\u001b[0m, \u001b[1;36m0.1242\u001b[0m, \u001b[1;36m0.1108\u001b[0m, \u001b[1;36m0.1565\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1435\u001b[0m, \u001b[1;36m0.2074\u001b[0m, \u001b[1;36m0.2046\u001b[0m, \u001b[1;36m0.1462\u001b[0m, \u001b[1;36m0.1263\u001b[0m, \u001b[1;36m0.1720\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1526\u001b[0m, \u001b[1;36m0.1958\u001b[0m, \u001b[1;36m0.1975\u001b[0m, \u001b[1;36m0.1367\u001b[0m, \u001b[1;36m0.1879\u001b[0m, \u001b[1;36m0.1295\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1385\u001b[0m, \u001b[1;36m0.2184\u001b[0m, \u001b[1;36m0.2128\u001b[0m, \u001b[1;36m0.1420\u001b[0m, \u001b[1;36m0.0988\u001b[0m, \u001b[1;36m0.1896\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4421</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5931</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5790</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4419</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6515</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5683</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4431</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6496</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5671</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4304</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6298</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5510</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4671</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5910</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5266</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4177</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6503</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5645</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.4421\u001b[0m, \u001b[1;36m0.5931\u001b[0m, \u001b[1;36m0.5790\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4419\u001b[0m, \u001b[1;36m0.6515\u001b[0m, \u001b[1;36m0.5683\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4431\u001b[0m, \u001b[1;36m0.6496\u001b[0m, \u001b[1;36m0.5671\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4304\u001b[0m, \u001b[1;36m0.6298\u001b[0m, \u001b[1;36m0.5510\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4671\u001b[0m, \u001b[1;36m0.5910\u001b[0m, \u001b[1;36m0.5266\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4177\u001b[0m, \u001b[1;36m0.6503\u001b[0m, \u001b[1;36m0.5645\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\n",
    "    \"\"\"First, we calculate attention scores for each pair of input vectors. <br><br> Then,\n",
    "    we normalize the scores with softmax to obtain attention weights. <br><br>\n",
    "    Finally, we calculate the context vector by taking the weighted sum of the input vectors.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "# Attention scores (covariance matrix)\n",
    "attn_scores = inputs @ inputs.T\n",
    "rprint(attn_scores)\n",
    "\n",
    "# Normalize to get attention weights\n",
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "rprint(attn_weights)\n",
    "\n",
    "# Context vectors\n",
    "all_context_vecs = attn_weights @ inputs\n",
    "rprint(all_context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attention with trainable weights\n",
    "\n",
    "Our next step will be to implement the self-attention mechanism used in the original transformer architecture, the GPT models, and most other popular LLMs. This self-attention mechanism is also called scaled dot-product attention.\n",
    "\n",
    "Weight parameters are the fundamental, learned coefficients that define the network’s connections, while attention weights are dynamic, context-specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The most notable difference is the introduction of weight matrices\n",
       "    that are updated during model training.<br><br> These trainable weight matrices\n",
       "    are crucial so that the model (specifically, the attention module\n",
       "    inside the model) can learn to produce \"good\" context vectors.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "First, we initialize three weight matrices: <code>W_query</code>, <code>W_key</code>,\n",
       "    and <code>W_value</code>. Each matrix has a shape of <code>(d_in, d_out)</code>.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Then we do a dot product of input <code>x(2)</code> with the query weight matrix\n",
       "    and the key weight matrix, respectively. The value weight matrix is not used\n",
       "    in this step. The query and key vectors are then used to calculate the attention\n",
       "    score between <code>x(2)</code> and each input vector.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4306</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4551</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.4306\u001b[0m, \u001b[1;36m1.4551\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "We successfully projected the six input tokens\n",
       "    from a three-dimensional onto a two-dimensional embedding space:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">keys.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>, values.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "keys.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, values.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The result for the unnormalized attention score is:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8524</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1.8524\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Calculate all attention scores via matrix multiplication:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2705</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8524</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8111</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0795</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5577</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5440</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.2705\u001b[0m, \u001b[1;36m1.8524\u001b[0m, \u001b[1;36m1.8111\u001b[0m, \u001b[1;36m1.0795\u001b[0m, \u001b[1;36m0.5577\u001b[0m, \u001b[1;36m1.5440\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Second element matches the previous calculation.\n",
       "    Next we normalize the attention scores to get attention weights.\n",
       "    There is a small difference in the normalization step. We divide by the square\n",
       "    root of the embedding dimension of the keys. <br><br>\n",
       "    <b>The scaling by the square root of the embedding dimension is the reason why this\n",
       "    self-attention mechanism is also called scaled-dot product attention.</b>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_k: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sqrt</span><span style=\"font-weight: bold\">(</span>d_k<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.41</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_k: \u001b[1;36m2\u001b[0m, \u001b[1;35mSqrt\u001b[0m\u001b[1m(\u001b[0md_k\u001b[1m)\u001b[0m: \u001b[1;36m1.41\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2264</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2199</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1311</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0906</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1820</span><span style=\"font-weight: bold\">])</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1500\u001b[0m, \u001b[1;36m0.2264\u001b[0m, \u001b[1;36m0.2199\u001b[0m, \u001b[1;36m0.1311\u001b[0m, \u001b[1;36m0.0906\u001b[0m, \u001b[1;36m0.1820\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "And finally we get context vector by calculating\n",
       "    a dot-product of the attention weights and the values.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3061</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8210</span><span style=\"font-weight: bold\">])</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1271</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3061\u001b[0m, \u001b[1;36m0.8210\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1.1271\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"The most notable difference is the introduction of weight matrices\n",
    "    that are updated during model training.<br><br> These trainable weight matrices\n",
    "    are crucial so that the model (specifically, the attention module\n",
    "    inside the model) can learn to produce \"good\" context vectors.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "# Select second input vector\n",
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"First, we initialize three weight matrices: <code>W_query</code>, <code>W_key</code>,\n",
    "    and <code>W_value</code>. Each matrix has a shape of <code>(d_in, d_out)</code>.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "W_query, W_key, W_value = [\n",
    "    torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False) for _ in range(3)\n",
    "]\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Then we do a dot product of input <code>x(2)</code> with the query weight matrix\n",
    "    and the key weight matrix, respectively. The value weight matrix is not used\n",
    "    in this step. The query and key vectors are then used to calculate the attention\n",
    "    score between <code>x(2)</code> and each input vector.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "query_2 = x_2 @ W_query \n",
    "key_2 = x_2 @ W_key \n",
    "value_2 = x_2 @ W_value\n",
    "rprint(query_2)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"We successfully projected the six input tokens\n",
    "    from a three-dimensional onto a two-dimensional embedding space:\"\"\"\n",
    "))\n",
    "\n",
    "keys = inputs @ W_key \n",
    "values = inputs @ W_value\n",
    "rprint(f\"keys.shape: {keys.shape}, values.shape: {values.shape}\")\n",
    "\n",
    "# Attention scores\n",
    "display(HTML(\n",
    "    \"\"\"The result for the unnormalized attention score is:\"\"\"\n",
    "))\n",
    "\n",
    "keys_2 = keys[1]\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "rprint(attn_score_22)\n",
    "\n",
    "# Attention scores\n",
    "display(HTML(\n",
    "    \"\"\"Calculate all attention scores via matrix multiplication:\"\"\"\n",
    "))\n",
    "\n",
    "# Attention scores against other vectors\n",
    "attn_scores_2 = query_2 @ keys.T\n",
    "rprint(attn_scores_2)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Second element matches the previous calculation.\n",
    "    Next we normalize the attention scores to get attention weights.\n",
    "    There is a small difference in the normalization step. We divide by the square\n",
    "    root of the embedding dimension of the keys. <br><br>\n",
    "    <b>The scaling by the square root of the embedding dimension is the reason why this\n",
    "    self-attention mechanism is also called scaled-dot product attention.</b>\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "# Normalize to get attention weights\n",
    "d_k = keys.shape[-1]\n",
    "rprint(f\"d_k: {d_k}, Sqrt(d_k): {d_k**0.5:.2f}\")\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "rprint(attn_weights_2, attn_weights_2.sum())\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"And finally we get context vector by calculating\n",
    "    a dot-product of the attention weights and the values.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "rprint(context_vec_2, context_vec_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Why query, key, and value?**\n",
    "\n",
    "The terms **key**, **query**, and **value** in the context of attention mechanisms are borrowed from the domain of information retrieval and databases, where similar concepts are used to store, search, and retrieve information.\n",
    "\n",
    "- A query is analogous to a search query in a database. It represents the current item (e.g., a word or token in a sentence) the model focuses on or tries to understand. The query is used to probe the other parts of the input sequence to determine how much attention to pay to them.\n",
    "\n",
    "- The key is like a database key used for indexing and searching. In the attention mechanism, each item in the input sequence (e.g., each word in a sentence) has an associated key. These keys are used to match the query.\n",
    "\n",
    "- The value in this context is similar to the value in a key-value pair in a database. It represents the actual content or representation of the input items. Once the model determines which keys (and thus which parts of the input) are most relevant to the query (the current focus item), it retrieves the corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Random initialization with <code>torch.rand()</code>:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2996</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8053</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3061</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8210</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3058</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8203</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2948</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7939</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2927</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7891</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2990</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8040</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">MmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.2996\u001b[0m, \u001b[1;36m0.8053\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.3061\u001b[0m, \u001b[1;36m0.8210\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.3058\u001b[0m, \u001b[1;36m0.8203\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2948\u001b[0m, \u001b[1;36m0.7939\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2927\u001b[0m, \u001b[1;36m0.7891\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2990\u001b[0m, \u001b[1;36m0.8040\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " Random initialization with <code>nn.Linear()</code>\n",
       "    helps to perform matrix multiplication without bias:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0739</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0713</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0748</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0703</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0749</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0702</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0760</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0685</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0763</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0679</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0754</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0693</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">MmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0739\u001b[0m,  \u001b[1;36m0.0713\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0748\u001b[0m,  \u001b[1;36m0.0703\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0749\u001b[0m,  \u001b[1;36m0.0702\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0760\u001b[0m,  \u001b[1;36m0.0685\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0763\u001b[0m,  \u001b[1;36m0.0679\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0754\u001b[0m,  \u001b[1;36m0.0693\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<code>nn.Linear</code> has an optimized weight\n",
       "    initialization scheme, contributing to more stable and\n",
       "    effective model training. <br><br>\n",
       "    Note that <code>SelfAttention_v1</code> and <code>SelfAttention_v2</code>\n",
       "    give different outputs because they use different initial weights\n",
       "    for the weight matrices since <code>nn.Linear</code> uses a more sophisticated\n",
       "    weight initialization scheme."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(123)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Random initialization with <code>torch.rand()</code>:\"\"\"\n",
    "))\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query, self.W_key, self.W_value = [\n",
    "            nn.Parameter(torch.rand(d_in, d_out)) for _ in range(3)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        attn_scores = queries @ keys.T  # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        return attn_weights @ values\n",
    "\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "rprint(sa_v1(inputs))\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\" Random initialization with <code>nn.Linear()</code>\n",
    "    helps to perform matrix multiplication without bias:\"\"\"\n",
    "))\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query, self.W_key, self.W_value = [\n",
    "            nn.Linear(d_in, d_out, bias=qkv_bias) for _ in range(3)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        return attn_weights @ values\n",
    "    \n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "rprint(sa_v2(inputs))\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"<code>nn.Linear</code> has an optimized weight\n",
    "    initialization scheme, contributing to more stable and\n",
    "    effective model training. <br><br>\n",
    "    Note that <code>SelfAttention_v1</code> and <code>SelfAttention_v2</code>\n",
    "    give different outputs because they use different initial weights\n",
    "    for the weight matrices since <code>nn.Linear</code> uses a more sophisticated\n",
    "    weight initialization scheme.\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head attention\n",
    "\n",
    "Each head learns different aspects of the data, allowing the model to simultaneously attend to information from different representation subspaces at different positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1921</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1646</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1550</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1721</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1510</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2041</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1659</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1662</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1496</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1665</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1477</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2036</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1659</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1662</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1498</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1664</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1480</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1869</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1667</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1668</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1571</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1661</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1564</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1830</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1669</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1670</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1588</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1658</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1585</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1663</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1542</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1529</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SoftmaxBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1921\u001b[0m, \u001b[1;36m0.1646\u001b[0m, \u001b[1;36m0.1652\u001b[0m, \u001b[1;36m0.1550\u001b[0m, \u001b[1;36m0.1721\u001b[0m, \u001b[1;36m0.1510\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2041\u001b[0m, \u001b[1;36m0.1659\u001b[0m, \u001b[1;36m0.1662\u001b[0m, \u001b[1;36m0.1496\u001b[0m, \u001b[1;36m0.1665\u001b[0m, \u001b[1;36m0.1477\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2036\u001b[0m, \u001b[1;36m0.1659\u001b[0m, \u001b[1;36m0.1662\u001b[0m, \u001b[1;36m0.1498\u001b[0m, \u001b[1;36m0.1664\u001b[0m, \u001b[1;36m0.1480\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1869\u001b[0m, \u001b[1;36m0.1667\u001b[0m, \u001b[1;36m0.1668\u001b[0m, \u001b[1;36m0.1571\u001b[0m, \u001b[1;36m0.1661\u001b[0m, \u001b[1;36m0.1564\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1830\u001b[0m, \u001b[1;36m0.1669\u001b[0m, \u001b[1;36m0.1670\u001b[0m, \u001b[1;36m0.1588\u001b[0m, \u001b[1;36m0.1658\u001b[0m, \u001b[1;36m0.1585\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1663\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1542\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1529\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSoftmaxBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<code>torch.tril</code> sets values above the diagonal to zero:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Setting attention weights to zero:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1921</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2041</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1659</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2036</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1659</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1662</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1869</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1667</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1668</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1571</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1830</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1669</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1670</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1588</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1658</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1663</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1542</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1529</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">MulBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1921\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2041\u001b[0m, \u001b[1;36m0.1659\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2036\u001b[0m, \u001b[1;36m0.1659\u001b[0m, \u001b[1;36m0.1662\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1869\u001b[0m, \u001b[1;36m0.1667\u001b[0m, \u001b[1;36m0.1668\u001b[0m, \u001b[1;36m0.1571\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1830\u001b[0m, \u001b[1;36m0.1669\u001b[0m, \u001b[1;36m0.1670\u001b[0m, \u001b[1;36m0.1588\u001b[0m, \u001b[1;36m0.1658\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1663\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1542\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1529\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMulBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Normalize to 1 on masked inputs:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5517</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4483</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3800</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3097</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3103</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2758</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2460</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2462</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2319</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2175</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1983</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1984</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1888</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1971</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1663</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1542</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1529</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">DivBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.5517\u001b[0m, \u001b[1;36m0.4483\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.3800\u001b[0m, \u001b[1;36m0.3097\u001b[0m, \u001b[1;36m0.3103\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2758\u001b[0m, \u001b[1;36m0.2460\u001b[0m, \u001b[1;36m0.2462\u001b[0m, \u001b[1;36m0.2319\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2175\u001b[0m, \u001b[1;36m0.1983\u001b[0m, \u001b[1;36m0.1984\u001b[0m, \u001b[1;36m0.1888\u001b[0m, \u001b[1;36m0.1971\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1663\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1542\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1529\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs) \n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "rprint(attn_weights)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"<code>torch.tril</code> sets values above the diagonal to zero:\"\"\"\n",
    "))\n",
    "\n",
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "rprint(mask_simple)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Setting attention weights to zero:\"\"\"\n",
    "))\n",
    "\n",
    "masked_simple = attn_weights * mask_simple\n",
    "rprint(masked_simple)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Normalize to 1 on masked inputs:\"\"\"\n",
    "))\n",
    "\n",
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "rprint(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "When applying dropout to an attention weight matrix with a rate of 50%, half of the elements in the matrix are randomly set to zero. To compensate for the reduction in active elements, the values of the remaining elements in the matrix are scaled up by a factor of 1/0.5 = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Batch: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Batch: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">context_vecs.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "context_vecs.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "class CausalAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_in, d_out, context_length,\n",
    "        dropout, qkv_bias=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query, self.W_key, self.W_value = [\n",
    "            nn.Linear(d_in, d_out, bias=qkv_bias) for _ in range(3)\n",
    "        ]\n",
    "  \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "           'mask',\n",
    "           torch.triu(\n",
    "               torch.ones(context_length, context_length),\n",
    "                diagonal=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2)\n",
    "        attn_scores.masked_fill_(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        return attn_weights @ values\n",
    "\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "rprint(f\"Batch: {batch.shape}\")\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "rprint(f\"context_vecs.shape: {context_vecs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking multiple single-head attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4519</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2216</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4772</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1063</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5874</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0058</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5891</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3257</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6300</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0632</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6202</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3860</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5675</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0843</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5478</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3589</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0981</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5321</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3428</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5299</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1081</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5077</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3493</span><span style=\"font-weight: bold\">]]</span>,\n",
       "\n",
       "        <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4519</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2216</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4772</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1063</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5874</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0058</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5891</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3257</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6300</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0632</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6202</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3860</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5675</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0843</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5478</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3589</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0981</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5321</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3428</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5299</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1081</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5077</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3493</span><span style=\"font-weight: bold\">]]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">CatBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.4519\u001b[0m,  \u001b[1;36m0.2216\u001b[0m,  \u001b[1;36m0.4772\u001b[0m,  \u001b[1;36m0.1063\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5874\u001b[0m,  \u001b[1;36m0.0058\u001b[0m,  \u001b[1;36m0.5891\u001b[0m,  \u001b[1;36m0.3257\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.6300\u001b[0m, \u001b[1;36m-0.0632\u001b[0m,  \u001b[1;36m0.6202\u001b[0m,  \u001b[1;36m0.3860\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5675\u001b[0m, \u001b[1;36m-0.0843\u001b[0m,  \u001b[1;36m0.5478\u001b[0m,  \u001b[1;36m0.3589\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5526\u001b[0m, \u001b[1;36m-0.0981\u001b[0m,  \u001b[1;36m0.5321\u001b[0m,  \u001b[1;36m0.3428\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5299\u001b[0m, \u001b[1;36m-0.1081\u001b[0m,  \u001b[1;36m0.5077\u001b[0m,  \u001b[1;36m0.3493\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.4519\u001b[0m,  \u001b[1;36m0.2216\u001b[0m,  \u001b[1;36m0.4772\u001b[0m,  \u001b[1;36m0.1063\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5874\u001b[0m,  \u001b[1;36m0.0058\u001b[0m,  \u001b[1;36m0.5891\u001b[0m,  \u001b[1;36m0.3257\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.6300\u001b[0m, \u001b[1;36m-0.0632\u001b[0m,  \u001b[1;36m0.6202\u001b[0m,  \u001b[1;36m0.3860\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5675\u001b[0m, \u001b[1;36m-0.0843\u001b[0m,  \u001b[1;36m0.5478\u001b[0m,  \u001b[1;36m0.3589\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5526\u001b[0m, \u001b[1;36m-0.0981\u001b[0m,  \u001b[1;36m0.5321\u001b[0m,  \u001b[1;36m0.3428\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5299\u001b[0m, \u001b[1;36m-0.1081\u001b[0m,  \u001b[1;36m0.5077\u001b[0m,  \u001b[1;36m0.3493\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mCatBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">context_vecs.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "context_vecs.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_in, d_out, context_length,\n",
    "        dropout, num_heads, qkv_bias=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [\n",
    "                CausalAttention(\n",
    "                    d_in,\n",
    "                    d_out,\n",
    "                    context_length,\n",
    "                    dropout,\n",
    "                    qkv_bias\n",
    "                ) \n",
    "             for _ in range(num_heads)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]  # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(\n",
    "    d_in, d_out, context_length, 0.0, num_heads=2\n",
    ")\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "rprint(context_vecs)\n",
    "rprint(f\"context_vecs.shape: {context_vecs.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "language-models-qT78hDLD-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
