{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Build a Large Language Model (from scratch)\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\">\n",
    "\n",
    "Author of notes: https://github.com/deburky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Coding attention mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context length\n",
    "\n",
    "* Context length determines how many tokens the model can attend to.\n",
    "\n",
    "* The context length is the number of tokens that the model can consider when making predictions. For example, if the context length is 512, the model can only look at the last 512 tokens when making a prediction.\n",
    "\n",
    "* The last token generated contains information about the previous tokens. The model uses this information to make predictions about the next token in the sequence.\n",
    "\n",
    "> In inference, context length includes the prompt and the tokens generated by the model. The model can only attend to the last 512 tokens, so if the prompt is 512 tokens long, the model can only generate one token at a time. If the prompt is 511 tokens long, the model can generate two tokens at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "EMB_DIM = 128\n",
    "CONTEXT_LENGTH = 1024\n",
    "\n",
    "# Token embeddings\n",
    "embeddings = torch.nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "emb_weights = embeddings.weight.data\n",
    "\n",
    "# Positional embeddings\n",
    "pos_embeddings = torch.nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "pos_weights = pos_embeddings.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([11846,  1905, 19843,  7581, 13627])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5851, -1.2503, -2.9723,  ..., -0.2092,  2.3059,  0.4104],\n",
       "         [ 2.2785, -1.0144, -0.3601,  ...,  1.2413,  0.1254, -0.1556],\n",
       "         [-0.9434, -0.4623,  0.9273,  ...,  0.3718,  1.0774, -1.3366],\n",
       "         ...,\n",
       "         [-0.6133,  1.6394, -1.4568,  ..., -0.1773, -0.0806, -1.7509],\n",
       "         [-0.2132, -1.5831, -2.8863,  ...,  2.2222,  4.4905, -0.2002],\n",
       "         [ 1.3369,  0.5410, -1.2254,  ...,  0.1226,  0.7172,  0.7807]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate an input token sequence of length `L`\n",
    "input_ids = torch.randint(0, VOCAB_SIZE, (1, 64))  # (batch=1, seq_len=64)\n",
    "position_ids = torch.arange(0, input_ids.size(1)).unsqueeze(0)  # (1, 64)\n",
    "\n",
    "print(\"Input IDs:\", input_ids[0][:5])\n",
    "\n",
    "# Get token + position embeddings\n",
    "tok_emb = embeddings(input_ids)        # shape: [1, 64, 128]\n",
    "pos_emb = pos_embeddings(position_ids) # shape: [1, 64, 128]\n",
    "\n",
    "# Combine them (element-wise addition)\n",
    "combined = tok_emb + pos_emb  # shape: [1, 64, 128]\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deburky/Library/Caches/pypoetry/virtualenvs/language-models-qT78hDLD-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  101, 19081,  2024,  ...,     0,     0,     0]])\n",
      "Token Embeddings Shape: torch.Size([1, 1024, 128])\n",
      "Combined Embedding Shape: torch.Size([1, 1024, 128])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Setup\n",
    "VOCAB_SIZE = 1000\n",
    "EMB_DIM = 128\n",
    "CONTEXT_LENGTH = 1024\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Transformers are powerful models for sequence data.\"\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", max_length=CONTEXT_LENGTH, truncation=True, padding=\"max_length\")\n",
    "\n",
    "input_ids = tokens[\"input_ids\"]   # shape: [1, CONTEXT_LENGTH]\n",
    "\n",
    "# Adjust vocab size\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "\n",
    "# Embedding layers\n",
    "embeddings = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "pos_embeddings = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "\n",
    "# Create position IDs\n",
    "position_ids = torch.arange(0, input_ids.size(1)).unsqueeze(0)\n",
    "\n",
    "# Get embeddings\n",
    "tok_emb = embeddings(input_ids)\n",
    "pos_emb = pos_embeddings(position_ids)\n",
    "combined = tok_emb + pos_emb  # shape: [1, CONTEXT_LENGTH, EMB_DIM]\n",
    "\n",
    "# Inspect\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"Token Embeddings Shape:\", tok_emb.shape)\n",
    "print(\"Combined Embedding Shape:\", combined.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attention (not trainable)\n",
    "\n",
    "Self-attention serves as the cornerstone of every LLM based on the transformer architecture.\n",
    "\n",
    "Self-attention is a mechanism that allows each position in the input sequence to consider the relevancy of, or “attend to,” all other positions in the same sequence when computing the representation of a sequence. Self-attention is a key component of contemporary LLMs based on the transformer architecture, such as the GPT series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "In self-attention, our goal is to calculate context vectors <code>z(i)</code>\n",
       "    for each element <code>x(i)</code> in the input sequence. A context vector can be\n",
       "    interpreted as an enriched embedding vector."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8700</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6600</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.5500\u001b[0m, \u001b[1;36m0.8700\u001b[0m, \u001b[1;36m0.6600\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9544</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4950</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4754</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8434</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7070</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0865</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.9544\u001b[0m, \u001b[1;36m1.4950\u001b[0m, \u001b[1;36m1.4754\u001b[0m, \u001b[1;36m0.8434\u001b[0m, \u001b[1;36m0.7070\u001b[0m, \u001b[1;36m1.0865\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The main goal behind the normalization is to obtain attention weights that sum up to 1.\n",
       "    In practice, it's more common and advisable to use the softmax function for normalization."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Attention weights: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1385</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2379</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1240</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1082</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1581</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Attention weights: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1385\u001b[0m, \u001b[1;36m0.2379\u001b[0m, \u001b[1;36m0.2333\u001b[0m, \u001b[1;36m0.1240\u001b[0m, \u001b[1;36m0.1082\u001b[0m, \u001b[1;36m0.1581\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sum: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sum: \u001b[1;36m1.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next step is calculating the context vector <code>z(2)</code> by multiplying\n",
       "    the embedded input tokens, <code>x(i)</code>, with the corresponding attention weights\n",
       "    and then summing the resulting vectors. Thus, context vector <code>z(2)</code> is the \n",
       "    weighted sum of all input vectors, obtained by multiplying each input vector\n",
       "    by its corresponding attention weight:\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4419</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6515</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5683</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.4419\u001b[0m, \u001b[1;36m0.6515\u001b[0m, \u001b[1;36m0.5683\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from rich import print as rprint\n",
    "from IPython.display import HTML\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"In self-attention, our goal is to calculate context vectors <code>z(i)</code>\n",
    "    for each element <code>x(i)</code> in the input sequence. A context vector can be\n",
    "    interpreted as an enriched embedding vector.\"\"\"\n",
    "))\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "\n",
    "rprint(inputs.shape)\n",
    "\n",
    "# Dot product of each input vector with the query vector\n",
    "query = inputs[1]\n",
    "rprint(query)\n",
    "\n",
    "# Attention scores\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "rprint(attn_scores_2)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"The main goal behind the normalization is to obtain attention weights that sum up to 1.\n",
    "    In practice, it's more common and advisable to use the softmax function for normalization.\"\"\"\n",
    "))\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "rprint(f\"Attention weights: {attn_weights_2}\")\n",
    "rprint(f\"Sum: {attn_weights_2.sum()}\")\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"The next step is calculating the context vector <code>z(2)</code> by multiplying\n",
    "    the embedded input tokens, <code>x(i)</code>, with the corresponding attention weights\n",
    "    and then summing the resulting vectors. Thus, context vector <code>z(2)</code> is the \n",
    "    weighted sum of all input vectors, obtained by multiplying each input vector\n",
    "    by its corresponding attention weight:\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "# Calculate context vector z(2)\n",
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "rprint(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The dot product is a measure of similarity because it quantifies how closely two vectors are aligned: a higher dot product indicates a greater degree of alignment or similarity between the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "First, we calculate attention scores for each pair of input vectors. <br><br> Then,\n",
       "    we normalize the scores with softmax to obtain attention weights. <br><br>\n",
       "    Finally, we calculate the context vector by taking the weighted sum of the input vectors.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9995</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9544</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9422</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4753</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4576</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6310</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9544</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4950</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4754</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8434</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7070</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0865</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9422</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4754</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4570</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8296</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7154</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0605</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4753</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8434</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8296</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4937</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3474</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6565</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4576</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7070</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7154</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3474</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6654</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2935</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6310</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0865</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0605</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6565</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9450</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.9995\u001b[0m, \u001b[1;36m0.9544\u001b[0m, \u001b[1;36m0.9422\u001b[0m, \u001b[1;36m0.4753\u001b[0m, \u001b[1;36m0.4576\u001b[0m, \u001b[1;36m0.6310\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.9544\u001b[0m, \u001b[1;36m1.4950\u001b[0m, \u001b[1;36m1.4754\u001b[0m, \u001b[1;36m0.8434\u001b[0m, \u001b[1;36m0.7070\u001b[0m, \u001b[1;36m1.0865\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.9422\u001b[0m, \u001b[1;36m1.4754\u001b[0m, \u001b[1;36m1.4570\u001b[0m, \u001b[1;36m0.8296\u001b[0m, \u001b[1;36m0.7154\u001b[0m, \u001b[1;36m1.0605\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4753\u001b[0m, \u001b[1;36m0.8434\u001b[0m, \u001b[1;36m0.8296\u001b[0m, \u001b[1;36m0.4937\u001b[0m, \u001b[1;36m0.3474\u001b[0m, \u001b[1;36m0.6565\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4576\u001b[0m, \u001b[1;36m0.7070\u001b[0m, \u001b[1;36m0.7154\u001b[0m, \u001b[1;36m0.3474\u001b[0m, \u001b[1;36m0.6654\u001b[0m, \u001b[1;36m0.2935\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.6310\u001b[0m, \u001b[1;36m1.0865\u001b[0m, \u001b[1;36m1.0605\u001b[0m, \u001b[1;36m0.6565\u001b[0m, \u001b[1;36m0.2935\u001b[0m, \u001b[1;36m0.9450\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2098</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2006</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1981</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1242</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1220</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1452</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1385</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2379</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1240</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1082</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1581</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1390</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2369</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2326</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1242</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1108</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1565</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1435</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2074</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2046</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1462</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1263</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1720</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1958</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1975</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1367</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1879</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1295</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1385</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2184</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1420</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0988</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1896</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.2098\u001b[0m, \u001b[1;36m0.2006\u001b[0m, \u001b[1;36m0.1981\u001b[0m, \u001b[1;36m0.1242\u001b[0m, \u001b[1;36m0.1220\u001b[0m, \u001b[1;36m0.1452\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1385\u001b[0m, \u001b[1;36m0.2379\u001b[0m, \u001b[1;36m0.2333\u001b[0m, \u001b[1;36m0.1240\u001b[0m, \u001b[1;36m0.1082\u001b[0m, \u001b[1;36m0.1581\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1390\u001b[0m, \u001b[1;36m0.2369\u001b[0m, \u001b[1;36m0.2326\u001b[0m, \u001b[1;36m0.1242\u001b[0m, \u001b[1;36m0.1108\u001b[0m, \u001b[1;36m0.1565\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1435\u001b[0m, \u001b[1;36m0.2074\u001b[0m, \u001b[1;36m0.2046\u001b[0m, \u001b[1;36m0.1462\u001b[0m, \u001b[1;36m0.1263\u001b[0m, \u001b[1;36m0.1720\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1526\u001b[0m, \u001b[1;36m0.1958\u001b[0m, \u001b[1;36m0.1975\u001b[0m, \u001b[1;36m0.1367\u001b[0m, \u001b[1;36m0.1879\u001b[0m, \u001b[1;36m0.1295\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1385\u001b[0m, \u001b[1;36m0.2184\u001b[0m, \u001b[1;36m0.2128\u001b[0m, \u001b[1;36m0.1420\u001b[0m, \u001b[1;36m0.0988\u001b[0m, \u001b[1;36m0.1896\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4421</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5931</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5790</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4419</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6515</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5683</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4431</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6496</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5671</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4304</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6298</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5510</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4671</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5910</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5266</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4177</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6503</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5645</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.4421\u001b[0m, \u001b[1;36m0.5931\u001b[0m, \u001b[1;36m0.5790\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4419\u001b[0m, \u001b[1;36m0.6515\u001b[0m, \u001b[1;36m0.5683\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4431\u001b[0m, \u001b[1;36m0.6496\u001b[0m, \u001b[1;36m0.5671\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4304\u001b[0m, \u001b[1;36m0.6298\u001b[0m, \u001b[1;36m0.5510\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4671\u001b[0m, \u001b[1;36m0.5910\u001b[0m, \u001b[1;36m0.5266\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.4177\u001b[0m, \u001b[1;36m0.6503\u001b[0m, \u001b[1;36m0.5645\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\n",
    "    \"\"\"First, we calculate attention scores for each pair of input vectors. <br><br> Then,\n",
    "    we normalize the scores with softmax to obtain attention weights. <br><br>\n",
    "    Finally, we calculate the context vector by taking the weighted sum of the input vectors.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "# Attention scores (covariance matrix)\n",
    "attn_scores = inputs @ inputs.T\n",
    "rprint(attn_scores)\n",
    "\n",
    "# Normalize to get attention weights\n",
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "rprint(attn_weights)\n",
    "\n",
    "# Context vectors\n",
    "all_context_vecs = attn_weights @ inputs\n",
    "rprint(all_context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attention (trainable)\n",
    "\n",
    "Our next step will be to implement the self-attention mechanism used in the original transformer architecture, the GPT models, and most other popular LLMs. This self-attention mechanism is also called scaled dot-product attention.\n",
    "\n",
    "Weight parameters are the fundamental, learned coefficients that define the network’s connections, while attention weights are dynamic, context-specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The most notable difference is the introduction of weight matrices\n",
       "    that are updated during model training.<br><br> These trainable weight matrices\n",
       "    are crucial so that the model (specifically, the attention module\n",
       "    inside the model) can learn to produce \"good\" context vectors.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "First, we initialize three weight matrices: <code>W_query</code>, <code>W_key</code>,\n",
       "    and <code>W_value</code>. Each matrix has a shape of <code>(d_in, d_out)</code>.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Then we do a dot product of input <code>x(2)</code> with the query weight matrix\n",
       "    and the key weight matrix, respectively. The value weight matrix is not used\n",
       "    in this step. The query and key vectors are then used to calculate the attention\n",
       "    score between <code>x(2)</code> and each input vector.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4306</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4551</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.4306\u001b[0m, \u001b[1;36m1.4551\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "We successfully projected the six input tokens from\n",
       "    a three-dimensional onto a two-dimensional embedding space:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">keys.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>, values.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "keys.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, values.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The result for the unnormalized attention score is:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8524</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1.8524\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Calculate all attention scores via matrix multiplication:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2705</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8524</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8111</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0795</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5577</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5440</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.2705\u001b[0m, \u001b[1;36m1.8524\u001b[0m, \u001b[1;36m1.8111\u001b[0m, \u001b[1;36m1.0795\u001b[0m, \u001b[1;36m0.5577\u001b[0m, \u001b[1;36m1.5440\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Second element matches the previous calculation.\n",
       "    Next we normalize the attention scores to get attention weights.\n",
       "    There is a small difference in the normalization step. We divide by the square\n",
       "    root of the embedding dimension of the keys. <br><br>\n",
       "    <b>The scaling by the square root of the embedding dimension is the reason why this\n",
       "    self-attention mechanism is also called scaled-dot product attention.</b>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_k: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sqrt</span><span style=\"font-weight: bold\">(</span>d_k<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.41</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_k: \u001b[1;36m2\u001b[0m, \u001b[1;35mSqrt\u001b[0m\u001b[1m(\u001b[0md_k\u001b[1m)\u001b[0m: \u001b[1;36m1.41\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2264</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2199</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1311</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0906</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1820</span><span style=\"font-weight: bold\">])</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1500\u001b[0m, \u001b[1;36m0.2264\u001b[0m, \u001b[1;36m0.2199\u001b[0m, \u001b[1;36m0.1311\u001b[0m, \u001b[1;36m0.0906\u001b[0m, \u001b[1;36m0.1820\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "And finally we get context vector by calculating\n",
       "    a dot-product of the attention weights and the values.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3061</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8210</span><span style=\"font-weight: bold\">])</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1271</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3061\u001b[0m, \u001b[1;36m0.8210\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1.1271\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"The most notable difference is the introduction of weight matrices\n",
    "    that are updated during model training.<br><br> These trainable weight matrices\n",
    "    are crucial so that the model (specifically, the attention module\n",
    "    inside the model) can learn to produce \"good\" context vectors.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "# Select second input vector\n",
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"First, we initialize three weight matrices: <code>W_query</code>, <code>W_key</code>,\n",
    "    and <code>W_value</code>. Each matrix has a shape of <code>(d_in, d_out)</code>.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "W_query, W_key, W_value = [\n",
    "    torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False) for _ in range(3)\n",
    "]\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Then we do a dot product of input <code>x(2)</code> with the query weight matrix\n",
    "    and the key weight matrix, respectively. The value weight matrix is not used\n",
    "    in this step. The query and key vectors are then used to calculate the attention\n",
    "    score between <code>x(2)</code> and each input vector.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "rprint(query_2)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"We successfully projected the six input tokens from\n",
    "    a three-dimensional onto a two-dimensional embedding space:\"\"\"\n",
    "))\n",
    "\n",
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "rprint(f\"keys.shape: {keys.shape}, values.shape: {values.shape}\")\n",
    "\n",
    "# Attention scores\n",
    "display(HTML(\n",
    "    \"\"\"The result for the unnormalized attention score is:\"\"\"\n",
    "))\n",
    "\n",
    "keys_2 = keys[1]\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "rprint(attn_score_22)\n",
    "\n",
    "# Attention scores\n",
    "display(HTML(\n",
    "    \"\"\"Calculate all attention scores via matrix multiplication:\"\"\"\n",
    "))\n",
    "\n",
    "# Attention scores against other vectors\n",
    "attn_scores_2 = query_2 @ keys.T\n",
    "rprint(attn_scores_2)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Second element matches the previous calculation.\n",
    "    Next we normalize the attention scores to get attention weights.\n",
    "    There is a small difference in the normalization step. We divide by the square\n",
    "    root of the embedding dimension of the keys. <br><br>\n",
    "    <b>The scaling by the square root of the embedding dimension is the reason why this\n",
    "    self-attention mechanism is also called scaled-dot product attention.</b>\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "# Normalize to get attention weights\n",
    "d_k = keys.shape[-1]\n",
    "rprint(f\"d_k: {d_k}, Sqrt(d_k): {d_k**0.5:.2f}\")\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "rprint(attn_weights_2, attn_weights_2.sum())\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"And finally we get context vector by calculating\n",
    "    a dot-product of the attention weights and the values.\n",
    "    \"\"\"\n",
    "))\n",
    "\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "rprint(context_vec_2, context_vec_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Why query, key, and value?**\n",
    "\n",
    "The terms **key**, **query**, and **value** in the context of attention mechanisms are borrowed from the domain of information retrieval and databases, where similar concepts are used to store, search, and retrieve information.\n",
    "\n",
    "- A query is analogous to a search query in a database. It represents the current item (e.g., a word or token in a sentence) the model focuses on or tries to understand. The query is used to probe the other parts of the input sequence to determine how much attention to pay to them.\n",
    "\n",
    "- The key is like a database key used for indexing and searching. In the attention mechanism, each item in the input sequence (e.g., each word in a sentence) has an associated key. These keys are used to match the query.\n",
    "\n",
    "- The value in this context is similar to the value in a key-value pair in a database. It represents the actual content or representation of the input items. Once the model determines which keys (and thus which parts of the input) are most relevant to the query (the current focus item), it retrieves the corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Random initialization with <code>torch.rand()</code>:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2996</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8053</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3061</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8210</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3058</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8203</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2948</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7939</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2927</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7891</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2990</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8040</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">MmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.2996\u001b[0m, \u001b[1;36m0.8053\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.3061\u001b[0m, \u001b[1;36m0.8210\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.3058\u001b[0m, \u001b[1;36m0.8203\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2948\u001b[0m, \u001b[1;36m0.7939\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2927\u001b[0m, \u001b[1;36m0.7891\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2990\u001b[0m, \u001b[1;36m0.8040\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Random initialization with <code>nn.Linear()</code>\n",
       "    helps to perform matrix multiplication without bias:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0739</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0713</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0748</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0703</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0749</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0702</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0760</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0685</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0763</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0679</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0754</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0693</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">MmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0739\u001b[0m,  \u001b[1;36m0.0713\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0748\u001b[0m,  \u001b[1;36m0.0703\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0749\u001b[0m,  \u001b[1;36m0.0702\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0760\u001b[0m,  \u001b[1;36m0.0685\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0763\u001b[0m,  \u001b[1;36m0.0679\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.0754\u001b[0m,  \u001b[1;36m0.0693\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<code>nn.Linear</code> has an optimized weight\n",
       "    initialization scheme, contributing to more stable and\n",
       "    effective model training. <br><br>\n",
       "    Note that <code>SelfAttention_v1</code> and <code>SelfAttention_v2</code>\n",
       "    give different outputs because they use different initial weights\n",
       "    for the weight matrices since <code>nn.Linear</code> uses a more sophisticated\n",
       "    weight initialization scheme."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(123)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Random initialization with <code>torch.rand()</code>:\"\"\"\n",
    "))\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query, self.W_key, self.W_value = [\n",
    "            nn.Parameter(torch.rand(d_in, d_out)) for _ in range(3)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        attn_scores = queries @ keys.T  # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        return attn_weights @ values\n",
    "\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "rprint(sa_v1(inputs))\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Random initialization with <code>nn.Linear()</code>\n",
    "    helps to perform matrix multiplication without bias:\"\"\"\n",
    "))\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query, self.W_key, self.W_value = [\n",
    "            nn.Linear(d_in, d_out, bias=qkv_bias) for _ in range(3)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        return attn_weights @ values\n",
    "    \n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "rprint(sa_v2(inputs))\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"<code>nn.Linear</code> has an optimized weight\n",
    "    initialization scheme, contributing to more stable and\n",
    "    effective model training. <br><br>\n",
    "    Note that <code>SelfAttention_v1</code> and <code>SelfAttention_v2</code>\n",
    "    give different outputs because they use different initial weights\n",
    "    for the weight matrices since <code>nn.Linear</code> uses a more sophisticated\n",
    "    weight initialization scheme.\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head attention\n",
    "\n",
    "Each head learns different aspects of the data, allowing the model to simultaneously attend to information from different representation subspaces at different positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1921</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1646</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1652</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1550</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1721</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1510</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2041</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1659</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1662</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1496</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1665</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1477</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2036</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1659</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1662</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1498</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1664</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1480</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1869</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1667</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1668</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1571</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1661</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1564</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1830</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1669</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1670</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1588</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1658</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1585</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1663</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1542</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1529</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SoftmaxBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1921\u001b[0m, \u001b[1;36m0.1646\u001b[0m, \u001b[1;36m0.1652\u001b[0m, \u001b[1;36m0.1550\u001b[0m, \u001b[1;36m0.1721\u001b[0m, \u001b[1;36m0.1510\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2041\u001b[0m, \u001b[1;36m0.1659\u001b[0m, \u001b[1;36m0.1662\u001b[0m, \u001b[1;36m0.1496\u001b[0m, \u001b[1;36m0.1665\u001b[0m, \u001b[1;36m0.1477\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2036\u001b[0m, \u001b[1;36m0.1659\u001b[0m, \u001b[1;36m0.1662\u001b[0m, \u001b[1;36m0.1498\u001b[0m, \u001b[1;36m0.1664\u001b[0m, \u001b[1;36m0.1480\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1869\u001b[0m, \u001b[1;36m0.1667\u001b[0m, \u001b[1;36m0.1668\u001b[0m, \u001b[1;36m0.1571\u001b[0m, \u001b[1;36m0.1661\u001b[0m, \u001b[1;36m0.1564\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1830\u001b[0m, \u001b[1;36m0.1669\u001b[0m, \u001b[1;36m0.1670\u001b[0m, \u001b[1;36m0.1588\u001b[0m, \u001b[1;36m0.1658\u001b[0m, \u001b[1;36m0.1585\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1663\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1542\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1529\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSoftmaxBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<code>torch.tril</code> sets values above the diagonal to zero:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Context length: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Context length: \u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Mask:\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Mask:\n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m., \u001b[1;36m1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Setting attention weights to zero:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1921</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2041</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1659</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2036</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1659</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1662</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1869</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1667</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1668</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1571</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1830</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1669</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1670</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1588</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1658</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1663</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1542</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1529</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">MulBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1921\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2041\u001b[0m, \u001b[1;36m0.1659\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2036\u001b[0m, \u001b[1;36m0.1659\u001b[0m, \u001b[1;36m0.1662\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1869\u001b[0m, \u001b[1;36m0.1667\u001b[0m, \u001b[1;36m0.1668\u001b[0m, \u001b[1;36m0.1571\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1830\u001b[0m, \u001b[1;36m0.1669\u001b[0m, \u001b[1;36m0.1670\u001b[0m, \u001b[1;36m0.1588\u001b[0m, \u001b[1;36m0.1658\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1663\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1542\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1529\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMulBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Normalize to 1 on masked inputs:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5517</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4483</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3800</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3097</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3103</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2758</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2460</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2462</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2319</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2175</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1983</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1984</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1888</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1971</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1663</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1542</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1529</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">DivBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.5517\u001b[0m, \u001b[1;36m0.4483\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.3800\u001b[0m, \u001b[1;36m0.3097\u001b[0m, \u001b[1;36m0.3103\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2758\u001b[0m, \u001b[1;36m0.2460\u001b[0m, \u001b[1;36m0.2462\u001b[0m, \u001b[1;36m0.2319\u001b[0m, \u001b[1;36m0.0000\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2175\u001b[0m, \u001b[1;36m0.1983\u001b[0m, \u001b[1;36m0.1984\u001b[0m, \u001b[1;36m0.1888\u001b[0m, \u001b[1;36m0.1971\u001b[0m, \u001b[1;36m0.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1663\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1542\u001b[0m, \u001b[1;36m0.1666\u001b[0m, \u001b[1;36m0.1529\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs) \n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "rprint(attn_weights)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"<code>torch.tril</code> sets values above the diagonal to zero:\"\"\"\n",
    "))\n",
    "\n",
    "context_length = attn_scores.shape[0]\n",
    "rprint(f\"Context length: {context_length}\")\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "rprint(f\"Mask:\\n{mask_simple}\")\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Setting attention weights to zero:\"\"\"\n",
    "))\n",
    "\n",
    "masked_simple = attn_weights * mask_simple\n",
    "rprint(masked_simple)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Normalize to 1 on masked inputs:\"\"\"\n",
    "))\n",
    "\n",
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "rprint(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "When applying dropout to an attention weight matrix with a rate of 50%, half of the elements in the matrix are randomly set to zero. To compensate for the reduction in active elements, the values of the remaining elements in the matrix are scaled up by a factor of 1/0.5 = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single attention head\n",
    "\n",
    "An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Batch: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Batch: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">context_vecs.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "context_vecs.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4519</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2216</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5874</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0058</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6300</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0632</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5675</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0843</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0981</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5299</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1081</span><span style=\"font-weight: bold\">]]</span>,\n",
       "\n",
       "        <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4519</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2216</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5874</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0058</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6300</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0632</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5675</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0843</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0981</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5299</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1081</span><span style=\"font-weight: bold\">]]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">UnsafeViewBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.4519\u001b[0m,  \u001b[1;36m0.2216\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5874\u001b[0m,  \u001b[1;36m0.0058\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.6300\u001b[0m, \u001b[1;36m-0.0632\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5675\u001b[0m, \u001b[1;36m-0.0843\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5526\u001b[0m, \u001b[1;36m-0.0981\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5299\u001b[0m, \u001b[1;36m-0.1081\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.4519\u001b[0m,  \u001b[1;36m0.2216\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5874\u001b[0m,  \u001b[1;36m0.0058\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.6300\u001b[0m, \u001b[1;36m-0.0632\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5675\u001b[0m, \u001b[1;36m-0.0843\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5526\u001b[0m, \u001b[1;36m-0.0981\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5299\u001b[0m, \u001b[1;36m-0.1081\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mUnsafeViewBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "class CausalAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_in, d_out, context_length,\n",
    "        dropout, qkv_bias=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query, self.W_key, self.W_value = [\n",
    "            nn.Linear(d_in, d_out, bias=qkv_bias) for _ in range(3)\n",
    "        ]\n",
    "  \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "           'mask',\n",
    "           torch.triu(\n",
    "               torch.ones(context_length, context_length),\n",
    "                diagonal=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2)\n",
    "        attn_scores.masked_fill_(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        return attn_weights @ values\n",
    "\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "rprint(f\"Batch: {batch.shape}\")\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "rprint(f\"context_vecs.shape: {context_vecs.shape}\")\n",
    "rprint(context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head attention\n",
    "\n",
    "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions.\n",
    "\n",
    "`torch.cat` performs concatenation along a specified dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4519</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2216</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4772</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1063</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5874</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0058</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5891</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3257</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6300</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0632</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6202</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3860</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5675</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0843</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5478</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3589</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0981</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5321</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3428</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5299</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1081</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5077</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3493</span><span style=\"font-weight: bold\">]]</span>,\n",
       "\n",
       "        <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4519</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2216</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4772</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1063</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5874</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0058</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5891</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3257</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6300</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0632</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6202</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3860</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5675</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0843</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5478</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3589</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0981</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5321</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3428</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5299</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1081</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5077</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3493</span><span style=\"font-weight: bold\">]]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">CatBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.4519\u001b[0m,  \u001b[1;36m0.2216\u001b[0m,  \u001b[1;36m0.4772\u001b[0m,  \u001b[1;36m0.1063\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5874\u001b[0m,  \u001b[1;36m0.0058\u001b[0m,  \u001b[1;36m0.5891\u001b[0m,  \u001b[1;36m0.3257\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.6300\u001b[0m, \u001b[1;36m-0.0632\u001b[0m,  \u001b[1;36m0.6202\u001b[0m,  \u001b[1;36m0.3860\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5675\u001b[0m, \u001b[1;36m-0.0843\u001b[0m,  \u001b[1;36m0.5478\u001b[0m,  \u001b[1;36m0.3589\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5526\u001b[0m, \u001b[1;36m-0.0981\u001b[0m,  \u001b[1;36m0.5321\u001b[0m,  \u001b[1;36m0.3428\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5299\u001b[0m, \u001b[1;36m-0.1081\u001b[0m,  \u001b[1;36m0.5077\u001b[0m,  \u001b[1;36m0.3493\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.4519\u001b[0m,  \u001b[1;36m0.2216\u001b[0m,  \u001b[1;36m0.4772\u001b[0m,  \u001b[1;36m0.1063\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5874\u001b[0m,  \u001b[1;36m0.0058\u001b[0m,  \u001b[1;36m0.5891\u001b[0m,  \u001b[1;36m0.3257\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.6300\u001b[0m, \u001b[1;36m-0.0632\u001b[0m,  \u001b[1;36m0.6202\u001b[0m,  \u001b[1;36m0.3860\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5675\u001b[0m, \u001b[1;36m-0.0843\u001b[0m,  \u001b[1;36m0.5478\u001b[0m,  \u001b[1;36m0.3589\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5526\u001b[0m, \u001b[1;36m-0.0981\u001b[0m,  \u001b[1;36m0.5321\u001b[0m,  \u001b[1;36m0.3428\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.5299\u001b[0m, \u001b[1;36m-0.1081\u001b[0m,  \u001b[1;36m0.5077\u001b[0m,  \u001b[1;36m0.3493\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mCatBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">context_vecs.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "context_vecs.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_in, d_out, context_length,\n",
    "        dropout, num_heads, qkv_bias=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [\n",
    "                CausalAttention(\n",
    "                    d_in,\n",
    "                    d_out,\n",
    "                    context_length,\n",
    "                    dropout,\n",
    "                    qkv_bias\n",
    "                ) \n",
    "             for _ in range(num_heads)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]  # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(\n",
    "    d_in, d_out, context_length, 0.0, num_heads=2\n",
    ")\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "rprint(context_vecs)\n",
    "rprint(f\"context_vecs.shape: {context_vecs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head attention with weight splits\n",
    "\n",
    "In softmax regression (multiclass classification), we train a single weight matrix for all classes instead of having separate classifiers for each class.\n",
    "\n",
    "In multi-head attention, we don't train separate weight matrices for each attention head. Instead, we stack multiple smaller weight matrices into a single large matrix, just like in softmax regression.\n",
    "\n",
    "---\n",
    "\n",
    "**What is different?**\n",
    "\n",
    "`MultiHeadAttentionWrapper`: *Concatenation of all heads → [batch, num_tokens, d_out * num_heads]*\n",
    "\n",
    "Each head's output is kept separate. Used in some custom implementations, but not in standard transformers.\n",
    "\n",
    "`MultiHeadAttention`: *Final projection to d_out → [batch, num_tokens, d_out]*\n",
    "\n",
    "This is a standard Transformer implementations (e.g., GPT, BERT). Used in official Transformer architectures (e.g., Vaswani’s original paper). We apply a final projection layer (`out_proj`) to mix the heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Taking a tensor <code>a</code>:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2745</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6584</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2775</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8573</span><span style=\"font-weight: bold\">]</span>,\n",
       "          <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8993</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0390</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9268</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7388</span><span style=\"font-weight: bold\">]</span>,\n",
       "          <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7179</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7058</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9156</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4340</span><span style=\"font-weight: bold\">]]</span>,\n",
       "\n",
       "         <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0772</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3565</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1479</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5331</span><span style=\"font-weight: bold\">]</span>,\n",
       "          <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4066</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2318</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4545</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9737</span><span style=\"font-weight: bold\">]</span>,\n",
       "          <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4606</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5159</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4220</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5786</span><span style=\"font-weight: bold\">]]]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.2745\u001b[0m, \u001b[1;36m0.6584\u001b[0m, \u001b[1;36m0.2775\u001b[0m, \u001b[1;36m0.8573\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m0.8993\u001b[0m, \u001b[1;36m0.0390\u001b[0m, \u001b[1;36m0.9268\u001b[0m, \u001b[1;36m0.7388\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m0.7179\u001b[0m, \u001b[1;36m0.7058\u001b[0m, \u001b[1;36m0.9156\u001b[0m, \u001b[1;36m0.4340\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0772\u001b[0m, \u001b[1;36m0.3565\u001b[0m, \u001b[1;36m0.1479\u001b[0m, \u001b[1;36m0.5331\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m0.4066\u001b[0m, \u001b[1;36m0.2318\u001b[0m, \u001b[1;36m0.4545\u001b[0m, \u001b[1;36m0.9737\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m0.4606\u001b[0m, \u001b[1;36m0.5159\u001b[0m, \u001b[1;36m0.4220\u001b[0m, \u001b[1;36m0.5786\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Now we perform a batched matrix multiplication\n",
       "    between the tensor itself and a view of the tensor\n",
       "    where we transposed the last two dimensions,\n",
       "    <code>num_tokens</code> and <code>head_dim</code>:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3208</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1631</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2879</span><span style=\"font-weight: bold\">]</span>,\n",
       "          <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1631</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2150</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8424</span><span style=\"font-weight: bold\">]</span>,\n",
       "          <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2879</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8424</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0402</span><span style=\"font-weight: bold\">]]</span>,\n",
       "\n",
       "         <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4391</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7003</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5903</span><span style=\"font-weight: bold\">]</span>,\n",
       "          <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7003</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3737</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0620</span><span style=\"font-weight: bold\">]</span>,\n",
       "          <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5903</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0620</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9912</span><span style=\"font-weight: bold\">]]]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.3208\u001b[0m, \u001b[1;36m1.1631\u001b[0m, \u001b[1;36m1.2879\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m1.1631\u001b[0m, \u001b[1;36m2.2150\u001b[0m, \u001b[1;36m1.8424\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m1.2879\u001b[0m, \u001b[1;36m1.8424\u001b[0m, \u001b[1;36m2.0402\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.4391\u001b[0m, \u001b[1;36m0.7003\u001b[0m, \u001b[1;36m0.5903\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m0.7003\u001b[0m, \u001b[1;36m1.3737\u001b[0m, \u001b[1;36m1.0620\u001b[0m\u001b[1m]\u001b[0m,\n",
       "          \u001b[1m[\u001b[0m\u001b[1;36m0.5903\u001b[0m, \u001b[1;36m1.0620\u001b[0m, \u001b[1;36m0.9912\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">First head\n",
       "\n",
       "a<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, :, :<span style=\"font-weight: bold\">]</span> @ a<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, :, :<span style=\"font-weight: bold\">]</span>.T:\n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3208</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1631</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2879</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1631</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2150</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8424</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2879</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8424</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0402</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "First head\n",
       "\n",
       "a\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, :, :\u001b[1m]\u001b[0m @ a\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, :, :\u001b[1m]\u001b[0m.T:\n",
       "\n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.3208\u001b[0m, \u001b[1;36m1.1631\u001b[0m, \u001b[1;36m1.2879\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1.1631\u001b[0m, \u001b[1;36m2.2150\u001b[0m, \u001b[1;36m1.8424\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1.2879\u001b[0m, \u001b[1;36m1.8424\u001b[0m, \u001b[1;36m2.0402\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Second head\n",
       "\n",
       "a<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, :, :<span style=\"font-weight: bold\">]</span> @ a<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, :, :<span style=\"font-weight: bold\">]</span>.T:\n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4391</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7003</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5903</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7003</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3737</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0620</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5903</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0620</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9912</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Second head\n",
       "\n",
       "a\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, :, :\u001b[1m]\u001b[0m @ a\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, :, :\u001b[1m]\u001b[0m.T:\n",
       "\n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.4391\u001b[0m, \u001b[1;36m0.7003\u001b[0m, \u001b[1;36m0.5903\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.7003\u001b[0m, \u001b[1;36m1.3737\u001b[0m, \u001b[1;36m1.0620\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.5903\u001b[0m, \u001b[1;36m1.0620\u001b[0m, \u001b[1;36m0.9912\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Now we perform a batched matrix multiplication\n",
       "    between the tensor itself and a view of the tensor\n",
       "    where we transposed the last two dimensions,\n",
       "    <code>num_tokens</code> and <code>head_dim</code>:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The results show that the output dimension is\n",
       "    directly controlled by the <code>d_out</code> argument:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3190</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4858</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2943</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3897</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2856</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3593</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2693</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3873</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2639</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3928</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2575</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4028</span><span style=\"font-weight: bold\">]]</span>,\n",
       "\n",
       "        <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3190</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4858</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2943</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3897</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2856</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3593</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2693</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3873</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2639</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3928</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2575</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4028</span><span style=\"font-weight: bold\">]]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ViewBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3190\u001b[0m, \u001b[1;36m0.4858\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2943\u001b[0m, \u001b[1;36m0.3897\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2856\u001b[0m, \u001b[1;36m0.3593\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2693\u001b[0m, \u001b[1;36m0.3873\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2639\u001b[0m, \u001b[1;36m0.3928\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2575\u001b[0m, \u001b[1;36m0.4028\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3190\u001b[0m, \u001b[1;36m0.4858\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2943\u001b[0m, \u001b[1;36m0.3897\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2856\u001b[0m, \u001b[1;36m0.3593\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2693\u001b[0m, \u001b[1;36m0.3873\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2639\u001b[0m, \u001b[1;36m0.3928\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m0.2575\u001b[0m, \u001b[1;36m0.4028\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mViewBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">context_vecs.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "context_vecs.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Taking a tensor <code>a</code>:\"\"\"\n",
    "))\n",
    "\n",
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "\n",
    "rprint(a.shape)\n",
    "rprint(a)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Now we perform a batched matrix multiplication\n",
    "    between the tensor itself and a view of the tensor\n",
    "    where we transposed the last two dimensions,\n",
    "    <code>num_tokens</code> and <code>head_dim</code>:\"\"\"\n",
    "))\n",
    "\n",
    "rprint(a @ a.transpose(2, 3))\n",
    "\n",
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "rprint(f\"First head\\n\\na[0, 0, :, :] @ a[0, 0, :, :].T:\\n\\n{first_res}\")\n",
    "\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "rprint(f\"Second head\\n\\na[0, 1, :, :] @ a[0, 1, :, :].T:\\n\\n{second_res}\")\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"Now we perform a batched matrix multiplication\n",
    "    between the tensor itself and a view of the tensor\n",
    "    where we transposed the last two dimensions,\n",
    "    <code>num_tokens</code> and <code>head_dim</code>:\"\"\"\n",
    "))\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"The results show that the output dimension is\n",
    "    directly controlled by the <code>d_out</code> argument:\"\"\"\n",
    "))\n",
    "    \n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "rprint(context_vecs)\n",
    "rprint(f\"context_vecs.shape: {context_vecs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.3 Initializing GPT-2 size attention modules**\n",
    "\n",
    "Using the `MultiHeadAttention` class, initialize a multi-head attention module that has the same number of attention heads as the smallest GPT-2 model (12 attention heads). Also ensure that you use the respective input and output embedding sizes similar to GPT-2 (768 dimensions). Note that the smallest GPT-2 model supports a context length of 1,024 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "In GPT models, input embeddings and outputs have the same dimensions:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0685</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0206</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3180</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1948</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1485</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2868</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1240</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0154</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2823</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1513</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2925</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0590</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0165</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2872</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0375</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1005</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3074</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0014</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0153</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2097</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0947</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0958</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3008</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0013</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0153</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2097</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0941</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0960</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3007</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0014</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0155</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2098</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0944</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0956</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3011</span><span style=\"font-weight: bold\">]]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ViewBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0685\u001b[0m,  \u001b[1;36m0.0206\u001b[0m, \u001b[1;36m-0.3180\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.1948\u001b[0m, \u001b[1;36m-0.1485\u001b[0m, \u001b[1;36m-0.2868\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.1240\u001b[0m, \u001b[1;36m-0.0154\u001b[0m, \u001b[1;36m-0.2823\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.1384\u001b[0m, \u001b[1;36m-0.1513\u001b[0m, \u001b[1;36m-0.2925\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.0590\u001b[0m, \u001b[1;36m-0.0165\u001b[0m, \u001b[1;36m-0.2872\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.0375\u001b[0m, \u001b[1;36m-0.1005\u001b[0m, \u001b[1;36m-0.3074\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[33m...\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.0014\u001b[0m, \u001b[1;36m-0.0153\u001b[0m, \u001b[1;36m-0.2097\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.0947\u001b[0m, \u001b[1;36m-0.0958\u001b[0m, \u001b[1;36m-0.3008\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.0013\u001b[0m, \u001b[1;36m-0.0153\u001b[0m, \u001b[1;36m-0.2097\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.0941\u001b[0m, \u001b[1;36m-0.0960\u001b[0m, \u001b[1;36m-0.3007\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.0014\u001b[0m, \u001b[1;36m-0.0155\u001b[0m, \u001b[1;36m-0.2098\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.0944\u001b[0m, \u001b[1;36m-0.0956\u001b[0m, \u001b[1;36m-0.3011\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mViewBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">context_vecs.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "context_vecs.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size, context_length, d_in = 1, 1024, 768\n",
    "d_out = 768\n",
    "n_heads = 12\n",
    "\n",
    "batch = torch.rand(batch_size, context_length, d_in)\n",
    "\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=n_heads)\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "display(HTML(\n",
    "    \"\"\"In GPT models, input embeddings and outputs have the same dimensions:\"\"\"\n",
    "))\n",
    "\n",
    "rprint(context_vecs)\n",
    "rprint(f\"context_vecs.shape: {context_vecs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection layer\n",
    "\n",
    "[Docs > torch.nn > MultiheadAttention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)\n",
    "\n",
    "```python\n",
    "multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "```\n",
    "\n",
    "L is the target sequence length, N is the batch size, and E is the embedding dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (L, N, E)\n",
    "from torch.nn import MultiheadAttention\n",
    "\n",
    "batch_size, context_length, d_in, embed_dim = 1, 1024, 768, 768\n",
    "\n",
    "# Create properly shaped input tensors [1024, 1, 768]\n",
    "q, k, v = [torch.rand(context_length, batch_size, d_in) for _ in range(3)]\n",
    "\n",
    "# # Convert to [context_length, batch_size, d_in]\n",
    "q, k, v = [t.transpose(0, 1) for t in [q, k, v]]\n",
    "\n",
    "# Initialize MultiheadAttention\n",
    "mha = MultiheadAttention(embed_dim, num_heads=12, dropout=0.0)\n",
    "\n",
    "# Compute attention\n",
    "context_vecs, context_weights = mha(q, k, v)\n",
    "\n",
    "rprint(context_vecs.shape)  # Expected: [1, 1024, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (N, L, E) \n",
    "from torch.nn import MultiheadAttention\n",
    "\n",
    "batch_size, context_length, d_in, embed_dim = 1, 1024, 768, 768\n",
    "\n",
    "# Create properly shaped input tensors [1024, 1, 768]\n",
    "q, k, v = [torch.rand(batch_size, context_length, embed_dim) for _ in range(3)]\n",
    "\n",
    "# Initialize MultiheadAttention\n",
    "mha = MultiheadAttention(embed_dim, num_heads=12, dropout=0.0, batch_first=True)\n",
    "\n",
    "# Compute attention\n",
    "context_vecs, context_weights = mha(q, k, v)\n",
    "\n",
    "rprint(context_vecs.shape)  # Expected: [1, 1024, 768]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "language-models-qT78hDLD-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
